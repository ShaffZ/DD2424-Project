{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "N = 10000 # number of samples per file\n",
    "D = 3072 # number of features (dimensions of each picture)\n",
    "K = 10 # number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadBatch(filename):\n",
    "\t\"\"\" Copied from the dataset website \"\"\"\n",
    "\timport pickle\n",
    "\twith open(filename, 'rb') as fo:\n",
    "\t\tdict = pickle.load(fo, encoding='bytes')\n",
    "\treturn dict\n",
    "\n",
    "def montage(W):\n",
    "\t\"\"\" Display the image for each label in W \"\"\"\n",
    "\tfig, ax = plt.subplots(2,5)\n",
    "\tfor i in range(2):\n",
    "\t\tfor j in range(5):\n",
    "\t\t\tim  = W[i*5+j,:].reshape(32,32,3, order='F')\n",
    "\t\t\tsim = (im-np.min(im[:]))/(np.max(im[:])-np.min(im[:]))\n",
    "\t\t\tsim = sim.transpose(1,0,2)\n",
    "\t\t\tax[i][j].imshow(sim, interpolation='nearest')\n",
    "\t\t\tax[i][j].set_title(\"y=\"+str(5*i+j))\n",
    "\t\t\tax[i][j].axis('off')\n",
    "\tplt.show()\n",
    "\n",
    "def loader(filepath):\n",
    "\n",
    "    dic = LoadBatch(\"Datasets\\\\\" + filepath)\n",
    "    data = dic[b'data'].T # shape = d x n = 3072 x 10000\n",
    "    labels = np.array(dic[b'labels']).flatten() # shape = n = 1000\n",
    "\n",
    "    y = np.zeros((K, N))\n",
    "    for i in range(N):\n",
    "        y[labels[i]][i] = 1\n",
    "\n",
    "    return data, y, labels\n",
    "\n",
    "def extended_loader():\n",
    "    Data = []\n",
    "    OneHot = []\n",
    "    Labels = []\n",
    "    for i in range(5):\n",
    "       D, H, L = loader(f\"data_batch_{i+1}\")\n",
    "       Data.append(D)\n",
    "       OneHot.append(H)\n",
    "       Labels.append(L)\n",
    "    return {\"Data\" :np.hstack(Data), \"OneHot\": np.hstack(np.array(OneHot)),\"Labels\" : np.hstack(Labels)}\n",
    "\n",
    "def val_split(data,val_per=0.02):\n",
    "    n_val = val_per * data[\"Labels\"].shape[0]\n",
    "    split = int(data[\"Labels\"].shape[0] - n_val)\n",
    "    train = {\"Data\" :data[\"Data\"][:, :split], \"OneHot\": data[\"OneHot\"][:, :split],\"Labels\" : data[\"Labels\"][:split]}\n",
    "    val = {\"Data\" :data[\"Data\"][:, split:], \"OneHot\": data[\"OneHot\"][:, split:],\"Labels\" : data[\"Labels\"][split:]}\n",
    "    return train, val\n",
    "\n",
    "def mean_std(train_X):\n",
    "    mean = np.mean(train_X, axis=1, keepdims=True)\n",
    "    std = np.std(train_X, axis=1, keepdims=True)\n",
    "    return mean, std\n",
    "\n",
    "def normalize(mean, std, X):\n",
    "    norm_X = (X - mean) / std\n",
    "    return norm_X\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: X=(3072, 50000), y=(10, 50000)\n",
      "Test: X=(3072, 10000), y=(10, 10000)\n"
     ]
    }
   ],
   "source": [
    "#load and split\n",
    "Data = extended_loader()\n",
    "\n",
    "train_X, train_Y, train_y = Data.values() # Data, one hot labels, labels\n",
    "test_X, test_Y, test_y = loader(\"test_batch\")\n",
    "\n",
    "print('Train: X=%s, y=%s' % (train_X.shape, train_Y.shape))\n",
    "print('Test: X=%s, y=%s' % (test_X.shape, test_Y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = torch.tensor(train_X)\n",
    "test_X = torch.tensor(test_X)\n",
    "train_Y = torch.tensor(train_Y) \n",
    "test_Y = torch.tensor(test_Y) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_norm = train_X / 255.0\n",
    "test_X_norm = test_X / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cifar10Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Cifar10Model,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=(3,3), padding=1),\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=(3,3), padding=1),\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=(3,3), padding=1),\n",
    "        self.conv4 = nn.Conv2d(64, 64, kernel_size=(3,3), padding=1),\n",
    "        \n",
    "        self.conv5 = nn.Conv2d(64, 128, kernel_size=(3,3), padding=1),\n",
    "        self.conv6 = nn.Conv2d(128, 128, kernel_size=(3,3), padding=1),\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "    \n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.relu(self.conv4(x))\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = self.relu(self.conv5(x))\n",
    "        x = self.relu(self.conv6(x))\n",
    "        x = self.pool3(x)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return self.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Cifar10Model()\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
